#!/usr/bin/env python3
"""
Clean up project directory - Remove old/duplicate files
Keep only the latest, most relevant files
"""

from pathlib import Path
import shutil
import os

def cleanup_project():
    """Clean up project directory"""
    
    print("=" * 80)
    print("PROJECT CLEANUP - REMOVING OLD/DUPLICATE FILES")
    print("=" * 80)
    
    project_root = Path.cwd()
    
    # Files/directories to remove
    to_remove = [
        # Old plot directories (keeping only latest)
        "plots_real",
        "plots_real_fixed", 
        "plots_enhanced_fixed",
        
        # Old/duplicate experiment scripts
        "run_experiments.py",  # Keep run_experiments_enhanced.py
        "run_experiments_fixed.py",  # Superseded by enhanced
        "run_ablation_study.py",  # Keep run_minimal_ablation.py
        "run_simple_ablation.py",  # Keep run_minimal_ablation.py
        
        # Old demo files
        "demo_enhanced_graphrag.py",  # Not needed anymore
        
        # Cache directories (can be regenerated)
        "embeddings_cache",
        "__pycache__",
        "src/__pycache__",
        "tests/__pycache__",
        
        # Old documentation that's been superseded
        "TROUBLESHOOTING.md",  # Info is in other docs
        "QUICK_FIX.md",  # Info is in other docs
        "SUCCESS_SUMMARY.md",  # Superseded by FINAL_SUMMARY
        "CHIIR26_PAPER_READY.md",  # Superseded by FINAL_SUMMARY
        "VISUALIZATION_SUMMARY.md",  # Info in other docs
        "QUICK_REFERENCE.md",  # Superseded
        "PROJECT_STRUCTURE.md",  # Outdated
        "IMPLEMENTATION_SUMMARY.md",  # Superseded
        
        # Temporary/test files
        "test_output",
        "temp",
        ".pytest_cache",
        
        # Old baseline file (empty)
        "baseline.py",
    ]
    
    print("\nğŸ—‘ï¸  Removing old/duplicate files...\n")
    
    removed_count = 0
    skipped_count = 0
    
    for item in to_remove:
        item_path = project_root / item
        
        if item_path.exists():
            try:
                if item_path.is_dir():
                    shutil.rmtree(item_path)
                    print(f"  âœ“ Removed directory: {item}/")
                else:
                    item_path.unlink()
                    print(f"  âœ“ Removed file: {item}")
                removed_count += 1
            except Exception as e:
                print(f"  âš ï¸  Could not remove {item}: {e}")
                skipped_count += 1
        else:
            skipped_count += 1
    
    print(f"\nğŸ“Š Cleanup summary:")
    print(f"  â€¢ Removed: {removed_count} items")
    print(f"  â€¢ Skipped (not found): {skipped_count} items")
    
    # Create a clean directory structure summary
    print("\n" + "=" * 80)
    print("CLEAN PROJECT STRUCTURE")
    print("=" * 80)
    
    print("""
ğŸ“ GCS/
â”œâ”€â”€ ğŸ“‚ src/                          # Source code
â”‚   â”œâ”€â”€ clip_embeddings.py          # CLIP model
â”‚   â”œâ”€â”€ graphRAG.py                 # GraphRAG system
â”‚   â”œâ”€â”€ ssm.py                      # SSM query processor
â”‚   â”œâ”€â”€ enhanced_graphrag.py        # Enhanced retriever
â”‚   â”œâ”€â”€ community_detection.py      # Community detection
â”‚   â”œâ”€â”€ community_summarization.py  # Summaries
â”‚   â”œâ”€â”€ evaluation.py               # Metrics & evaluation
â”‚   â”œâ”€â”€ visualization.py            # Plotting
â”‚   â”œâ”€â”€ data_utils.py               # Data loading
â”‚   â”œâ”€â”€ model_config.py             # Model configs
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                        # Test files
â”‚   â””â”€â”€ test_enhanced_graphrag.py
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                      # Utility scripts
â”‚   â””â”€â”€ balanced_sampling.py        # Data balancing
â”‚
â”œâ”€â”€ ğŸ“‚ data/                         # Raw datasets
â”‚   â”œâ”€â”€ AlzheimerDataset/
â”‚   â”œâ”€â”€ brain-tumor-mri-dataset/
â”‚   â”œâ”€â”€ ms_slices_central/
â”‚   â””â”€â”€ parkinsons_dataset_processed/
â”‚
â”œâ”€â”€ ğŸ“‚ balanced_data/                # Balanced datasets
â”‚   â”œâ”€â”€ balanced_alzheimer/
â”‚   â”œâ”€â”€ balanced_brain_tumor/
â”‚   â”œâ”€â”€ balanced_parkinson/
â”‚   â”œâ”€â”€ balanced_ms/
â”‚   â””â”€â”€ balanced_data_utils.py
â”‚
â”œâ”€â”€ ğŸ“‚ experiments/                  # Experiment results
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ evaluation_results_enhanced.json  âœ… Main results
â”‚       â””â”€â”€ ablation_results.json            âœ… Ablation study
â”‚
â”œâ”€â”€ ğŸ“‚ plots_enhanced/               # Main visualizations
â”‚   â”œâ”€â”€ comparison/
â”‚   â”‚   â”œâ”€â”€ baseline_comparison.pdf  âœ…
â”‚   â”‚   â””â”€â”€ query_time.pdf
â”‚   â”œâ”€â”€ graphrag/
â”‚   â”‚   â””â”€â”€ hierarchical_graph.pdf
â”‚   â””â”€â”€ community/
â”‚       â””â”€â”€ community_stats.pdf
â”‚
â”œâ”€â”€ ğŸ“‚ plots_by_disease/             # Disease-specific plots
â”‚   â”œâ”€â”€ performance_by_disease_bars.pdf     âœ… NEW!
â”‚   â”œâ”€â”€ performance_by_disease_grouped.pdf  âœ… NEW!
â”‚   â”œâ”€â”€ performance_by_disease_heatmap.pdf  âœ… NEW!
â”‚   â””â”€â”€ query_distribution_by_disease.pdf   âœ… NEW!
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ GRAPHRAG_APPROACH.md
â”‚
â”œâ”€â”€ ğŸ Main Scripts:
â”‚   â”œâ”€â”€ run_experiments_enhanced.py  âœ… Main experiment (21 queries)
â”‚   â”œâ”€â”€ run_minimal_ablation.py      âœ… Ablation study
â”‚   â”œâ”€â”€ plot_by_disease.py           âœ… Disease plots
â”‚   â”œâ”€â”€ regenerate_plots.py          âœ… Regenerate all plots
â”‚   â”œâ”€â”€ demo_plots.py                   Synthetic demo
â”‚   â””â”€â”€ main.py                         Entry point
â”‚
â”œâ”€â”€ ğŸ“„ Key Documentation:
â”‚   â”œâ”€â”€ FINAL_SUMMARY_CHIIR26.md     âœ… Complete project summary
â”‚   â”œâ”€â”€ ENHANCED_RESULTS_SUMMARY.md  âœ… Main results analysis
â”‚   â”œâ”€â”€ ABLATION_STUDY_RESULTS.md    âœ… Ablation analysis
â”‚   â”œâ”€â”€ EVALUATION_GUIDE.md          âœ… Methodology
â”‚   â”œâ”€â”€ PLOT_GUIDE.md                   Plot reference
â”‚   â””â”€â”€ CHIIR26_SUMMARY.md              Paper outline
â”‚
â”œâ”€â”€ âš™ï¸ Configuration:
â”‚   â”œâ”€â”€ requirements.txt             # Dependencies
â”‚   â”œâ”€â”€ setup.py                     # Package setup
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ ReadMe                       # Original readme
â”‚
â””â”€â”€ ğŸ§ª Utilities:
    â”œâ”€â”€ run_tests.py                 # Test runner
    â””â”€â”€ cleanup_project.py           # This script
    """)
    
    print("\n" + "=" * 80)
    print("âœ… PROJECT CLEANED UP!")
    print("=" * 80)
    
    print("\nğŸ“Œ Key Files to Use:")
    print("  â€¢ Run experiments: python run_experiments_enhanced.py")
    print("  â€¢ Ablation study: python run_minimal_ablation.py")
    print("  â€¢ Disease plots: python plot_by_disease.py")
    print("  â€¢ Regenerate plots: python regenerate_plots.py")
    
    print("\nğŸ“Š Results & Plots:")
    print("  â€¢ Main results: experiments/results/evaluation_results_enhanced.json")
    print("  â€¢ Ablation: experiments/results/ablation_results.json")
    print("  â€¢ Main plots: plots_enhanced/")
    print("  â€¢ Disease plots: plots_by_disease/")
    
    print("\nğŸ“š Documentation:")
    print("  â€¢ Project summary: FINAL_SUMMARY_CHIIR26.md")
    print("  â€¢ Results analysis: ENHANCED_RESULTS_SUMMARY.md")
    print("  â€¢ Ablation analysis: ABLATION_STUDY_RESULTS.md")
    
    # Count remaining files
    print("\nğŸ“ˆ Project Statistics:")
    
    py_files = list(project_root.glob("*.py"))
    md_files = list(project_root.glob("*.md"))
    src_files = list((project_root / "src").glob("*.py")) if (project_root / "src").exists() else []
    
    print(f"  â€¢ Python scripts (root): {len(py_files)}")
    print(f"  â€¢ Source files (src/): {len(src_files)}")
    print(f"  â€¢ Documentation files: {len(md_files)}")
    
    result_files = list((project_root / "experiments/results").glob("*.json")) if (project_root / "experiments/results").exists() else []
    print(f"  â€¢ Result files: {len(result_files)}")
    
    plot_dirs = ["plots_enhanced", "plots_by_disease"]
    total_plots = 0
    for plot_dir in plot_dirs:
        if (project_root / plot_dir).exists():
            plots = list((project_root / plot_dir).rglob("*.pdf"))
            total_plots += len(plots)
            print(f"  â€¢ Plots in {plot_dir}/: {len(plots)}")
    
    print(f"  â€¢ Total plots: {total_plots}")
    
    return removed_count

if __name__ == "__main__":
    try:
        removed = cleanup_project()
        print(f"\nğŸ‰ Successfully cleaned up project! ({removed} items removed)")
    except Exception as e:
        print(f"\nâŒ Error during cleanup: {e}")
        import traceback
        traceback.print_exc()

