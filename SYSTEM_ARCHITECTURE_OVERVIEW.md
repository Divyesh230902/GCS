# ğŸ—ï¸ System Architecture Overview - How Everything Works Together

**Your GraphRAG Medical Image Retrieval System**

---

## ğŸ“‹ **HIGH-LEVEL ARCHITECTURE**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER QUERY                               â”‚
â”‚         "Find mild Alzheimer cases with atrophy"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUERY PROCESSING (SSM/Mamba)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. Intent Detection: "Find" â†’ Local Search              â”‚   â”‚
â”‚  â”‚  2. Entity Extraction: "mild Alzheimer", "atrophy"       â”‚   â”‚
â”‚  â”‚  3. Search Mode Selection: Global/Local/Hybrid           â”‚   â”‚
â”‚  â”‚  4. Generate Text Embedding: CLIP text encoder           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HIERARCHICAL KNOWLEDGE GRAPH                        â”‚
â”‚                                                                   â”‚
â”‚  Level 0 (Global): Disease Communities                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Alzheimer   â”‚ Brain Tumor  â”‚ Parkinson's  â”‚    MS      â”‚    â”‚
â”‚  â”‚ (100 imgs)  â”‚ (100 imgs)   â”‚ (100 imgs)   â”‚ (100 imgs) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚             â”‚              â”‚             â”‚             â”‚
â”‚  Level 1 (Mid): Visual Similarity Clusters                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ L1_C0       â”‚ L1_C1       â”‚ L1_C2      â”‚ L1_C3         â”‚    â”‚
â”‚  â”‚ (Mild)      â”‚ (Moderate)  â”‚ (Severe)   â”‚ (Early)       â”‚    â”‚
â”‚  â”‚ 15 imgs     â”‚ 12 imgs     â”‚ 10 imgs    â”‚ 13 imgs       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚             â”‚               â”‚           â”‚              â”‚
â”‚  Level 2 (Local): Fine-grained Classes                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ L2_C0       â”‚ L2_C1       â”‚ L2_C2       â”‚ L2_C3       â”‚    â”‚
â”‚  â”‚ (Specific)  â”‚ (Specific)  â”‚ (Specific)  â”‚ (Specific)  â”‚    â”‚
â”‚  â”‚ 5-8 imgs    â”‚ 4-7 imgs    â”‚ 6-9 imgs    â”‚ 5-8 imgs    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                   â”‚
â”‚  Total: 44 Communities across 3 Levels                           â”‚
â”‚  Nodes: 400 images + metadata                                    â”‚
â”‚  Edges: 75,625 similarity connections                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MULTI-STRATEGY RETRIEVAL                        â”‚
â”‚                                                                   â”‚
â”‚  If Mode = GLOBAL:                                               â”‚
â”‚    â†’ Search community summaries                                  â”‚
â”‚    â†’ Return top-K communities                                    â”‚
â”‚    â†’ Aggregate images from communities                           â”‚
â”‚                                                                   â”‚
â”‚  If Mode = LOCAL:                                                â”‚
â”‚    â†’ Direct similarity search in embeddings                      â”‚
â”‚    â†’ Return top-K most similar images                            â”‚
â”‚                                                                   â”‚
â”‚  If Mode = HYBRID:                                               â”‚
â”‚    â†’ Combine community + similarity                              â”‚
â”‚    â†’ Weighted ranking                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RANKING & RESULTS                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Top-K Images (K=1,3,5,10):                              â”‚   â”‚
â”‚  â”‚    1. patient_123.jpg (score: 0.95)                      â”‚   â”‚
â”‚  â”‚       Community: L0_C0_alzheimer â†’ L1_C2 â†’ L2_C5         â”‚   â”‚
â”‚  â”‚       Explanation: "Mild atrophy pattern"                â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚    2. patient_456.jpg (score: 0.89)                      â”‚   â”‚
â”‚  â”‚       Community: L0_C0_alzheimer â†’ L1_C2 â†’ L2_C5         â”‚   â”‚
â”‚  â”‚       Explanation: "Similar hippocampal changes"         â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚    3. patient_789.jpg (score: 0.85)                      â”‚   â”‚
â”‚  â”‚       ...                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ **DATA STORAGE STRUCTURE**

### **1. File System Storage**

```
GCS/
â”‚
â”œâ”€â”€ balanced_data/                    # Raw Images
â”‚   â”œâ”€â”€ balanced_alzheimer/
â”‚   â”‚   â”œâ”€â”€ mild dementia/
â”‚   â”‚   â”‚   â”œâ”€â”€ alzheimer_001.jpg    â† Original images
â”‚   â”‚   â”‚   â”œâ”€â”€ alzheimer_002.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ moderate/
â”‚   â”‚   â””â”€â”€ severe/
â”‚   â”œâ”€â”€ balanced_brain_tumor/
â”‚   â”œâ”€â”€ balanced_parkinson/
â”‚   â””â”€â”€ balanced_ms/
â”‚
â”œâ”€â”€ embeddings_cache/                 # Pre-computed Embeddings
â”‚   â”œâ”€â”€ alzheimer_embeddings.pkl      â† CLIP features (512-dim)
â”‚   â”œâ”€â”€ brain_tumor_embeddings.pkl    â† Cached for speed
â”‚   â”œâ”€â”€ parkinson_embeddings.pkl
â”‚   â””â”€â”€ ms_embeddings.pkl
â”‚
â””â”€â”€ experiments/
    â””â”€â”€ results/
        â””â”€â”€ evaluation_results_enhanced.json  â† Performance metrics
```

### **2. In-Memory Data Structures**

```python
# When system runs, it loads everything into memory:

system_state = {
    # 1. Image Embeddings (400 images Ã— 512 dimensions)
    'image_embeddings': [
        ImageEmbedding(
            image_path='balanced_data/alzheimer/.../img_001.jpg',
            embedding=np.array([0.12, -0.45, ...]),  # 512-dim vector
            class_label='mild dementia',
            dataset='alzheimer'
        ),
        ...  # 400 total
    ],
    
    # 2. Knowledge Graph (NetworkX graph object)
    'graph': {
        'nodes': {
            'img_001': {
                'embedding': np.array([...]),
                'class': 'mild dementia',
                'dataset': 'alzheimer',
                'community_l0': 'L0_C0_alzheimer',
                'community_l1': 'L1_C2',
                'community_l2': 'L2_C5'
            },
            ...  # 400 nodes
        },
        'edges': [
            ('img_001', 'img_002', {'weight': 0.87}),  # Similarity
            ('img_001', 'img_045', {'weight': 0.76}),
            ...  # 75,625 edges
        ]
    },
    
    # 3. Hierarchical Communities (44 total)
    'communities': {
        'level_0': {
            'L0_C0_alzheimer': {
                'members': ['img_001', 'img_002', ..., 'img_100'],
                'centroid': np.array([...]),
                'summary': 'Alzheimer disease patterns with varying severity'
            },
            'L0_C1_brain_tumor': {...},
            'L0_C2_parkinson': {...},
            'L0_C3_ms': {...}
        },
        'level_1': {
            'L1_C0': {
                'parent': 'L0_C0_alzheimer',
                'members': ['img_001', 'img_015', ..., 'img_023'],
                'centroid': np.array([...]),
                'summary': 'Mild cognitive decline subgroup'
            },
            'L1_C1': {...},
            ...  # ~16 communities
        },
        'level_2': {
            'L2_C0': {
                'parent': 'L1_C0',
                'members': ['img_001', 'img_004', 'img_007'],
                'centroid': np.array([...]),
                'summary': 'Early hippocampal atrophy'
            },
            ...  # ~24 communities
        }
    },
    
    # 4. Node Embeddings Index (for fast lookup)
    'node_embeddings': {
        'img_001': np.array([0.12, -0.45, ...]),  # 512-dim
        'img_002': np.array([0.34, 0.23, ...]),
        ...  # 400 entries
    },
    
    # 5. Metadata Index
    'node_metadata': {
        'img_001': {
            'path': 'balanced_data/alzheimer/.../img_001.jpg',
            'class': 'mild dementia',
            'dataset': 'alzheimer',
            'communities': ['L0_C0_alzheimer', 'L1_C2', 'L2_C5']
        },
        ...  # 400 entries
    }
}
```

---

## ğŸ”„ **QUERY PROCESSING FLOW**

### **Step-by-Step: What Happens When User Queries**

```
USER: "Find mild Alzheimer cases with atrophy"
  â”‚
  â”‚ 1. Query enters system
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SSM/MAMBA QUERY PROCESSOR (src/ssm.py)                      â”‚
â”‚                                                              â”‚
â”‚ A. Intent Detection (Rule-based currently):                 â”‚
â”‚    - Scans for keywords: "find", "show", "compare", "all"   â”‚
â”‚    - Result: "find" â†’ Local Search Mode                     â”‚
â”‚                                                              â”‚
â”‚ B. Entity Extraction:                                       â”‚
â”‚    - Extracts: ["mild", "Alzheimer", "atrophy"]            â”‚
â”‚    - Maps to: disease="alzheimer", severity="mild"          â”‚
â”‚                                                              â”‚
â”‚ C. Query Embedding Generation:                              â”‚
â”‚    query_text = "Find mild Alzheimer cases with atrophy"    â”‚
â”‚    query_embedding = CLIP.get_text_features(query_text)     â”‚
â”‚    â†’ Result: 512-dim vector [0.23, -0.12, 0.45, ...]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RETRIEVAL STRATEGY SELECTION (src/enhanced_graphrag.py)     â”‚
â”‚                                                              â”‚
â”‚ Based on intent:                                            â”‚
â”‚   IF "find/specific" â†’ LOCAL SEARCH                         â”‚
â”‚   IF "all/show/compare" â†’ GLOBAL SEARCH                     â”‚
â”‚   ELSE â†’ HYBRID SEARCH                                      â”‚
â”‚                                                              â”‚
â”‚ Selected: LOCAL SEARCH                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LOCAL SEARCH EXECUTION                                       â”‚
â”‚                                                              â”‚
â”‚ 1. Compute Similarity:                                      â”‚
â”‚    for each image_emb in node_embeddings:                   â”‚
â”‚        similarity = cosine(query_embedding, image_emb)      â”‚
â”‚                                                              â”‚
â”‚ 2. Sort by Similarity:                                      â”‚
â”‚    [                                                         â”‚
â”‚      (img_045, 0.92),  â† Most similar                       â”‚
â”‚      (img_012, 0.89),                                        â”‚
â”‚      (img_078, 0.87),                                        â”‚
â”‚      (img_023, 0.85),                                        â”‚
â”‚      (img_091, 0.83),                                        â”‚
â”‚      ...                                                     â”‚
â”‚    ]                                                         â”‚
â”‚                                                              â”‚
â”‚ 3. Get Top-K (K=5):                                         â”‚
â”‚    top_results = results[:5]                                â”‚
â”‚                                                              â”‚
â”‚ 4. Enrich with Context:                                     â”‚
â”‚    For each result:                                         â”‚
â”‚      - Load image metadata                                  â”‚
â”‚      - Get community path (L0 â†’ L1 â†’ L2)                   â”‚
â”‚      - Generate explanation                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULT RANKING & EXPLANATION                                 â”‚
â”‚                                                              â”‚
â”‚ Results = [                                                  â”‚
â”‚   {                                                          â”‚
â”‚     'rank': 1,                                              â”‚
â”‚     'image': 'img_045',                                     â”‚
â”‚     'path': 'balanced_data/.../alzheimer_045.jpg',          â”‚
â”‚     'similarity': 0.92,                                     â”‚
â”‚     'class': 'mild dementia',                               â”‚
â”‚     'dataset': 'alzheimer',                                 â”‚
â”‚     'community_path': [                                     â”‚
â”‚       'L0_C0_alzheimer',                                    â”‚
â”‚       'L1_C2',                                              â”‚
â”‚       'L2_C5'                                               â”‚
â”‚     ],                                                      â”‚
â”‚     'explanation': 'From mild cognitive decline subgroup    â”‚
â”‚                     showing hippocampal atrophy patterns',  â”‚
â”‚     'confidence': 0.92                                      â”‚
â”‚   },                                                         â”‚
â”‚   { rank: 2, ... },                                         â”‚
â”‚   { rank: 3, ... },                                         â”‚
â”‚   { rank: 4, ... },                                         â”‚
â”‚   { rank: 5, ... }                                          â”‚
â”‚ ]                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RETURN TO USER                                               â”‚
â”‚                                                              â”‚
â”‚ Display: Top-5 Images with Explanations                     â”‚
â”‚ Time: 71ms                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  **MAMBA/SSM COMMUNICATION FLOW**

### **Current Implementation**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SSMQueryProcessor Class (src/ssm.py)                        â”‚
â”‚                                                              â”‚
â”‚ Currently implements TWO modes:                             â”‚
â”‚                                                              â”‚
â”‚ 1. RULE-BASED MODE (Active by default):                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ def process_query(query_text):                   â”‚    â”‚
â”‚    â”‚     # Keyword matching                            â”‚    â”‚
â”‚    â”‚     if "find" in query or "specific" in query:   â”‚    â”‚
â”‚    â”‚         intent = "local_search"                   â”‚    â”‚
â”‚    â”‚     elif "all" in query or "show" in query:      â”‚    â”‚
â”‚    â”‚         intent = "global_search"                  â”‚    â”‚
â”‚    â”‚     else:                                         â”‚    â”‚
â”‚    â”‚         intent = "hybrid_search"                  â”‚    â”‚
â”‚    â”‚                                                   â”‚    â”‚
â”‚    â”‚     return QueryResult(                           â”‚    â”‚
â”‚    â”‚         intent=intent,                            â”‚    â”‚
â”‚    â”‚         entities=extract_entities(query_text),    â”‚    â”‚
â”‚    â”‚         embedding=clip.get_text_features(...)     â”‚    â”‚
â”‚    â”‚     )                                             â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚ 2. MAMBA MODE (Available but not active):                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ def _load_model():                                â”‚    â”‚
â”‚    â”‚     from transformers import MambaForCausalLM     â”‚    â”‚
â”‚    â”‚     model = MambaForCausalLM.from_pretrained(     â”‚    â”‚
â”‚    â”‚         "state-spaces/mamba-130m-hf"              â”‚    â”‚
â”‚    â”‚     )                                             â”‚    â”‚
â”‚    â”‚                                                   â”‚    â”‚
â”‚    â”‚ def generate_with_mamba(query):                   â”‚    â”‚
â”‚    â”‚     prompt = f"Analyze query: {query}\n"         â”‚    â”‚
â”‚    â”‚     prompt += "Intent (local/global/hybrid): "    â”‚    â”‚
â”‚    â”‚     response = model.generate(prompt)             â”‚    â”‚
â”‚    â”‚     # Parse Mamba output                          â”‚    â”‚
â”‚    â”‚     return parsed_intent                          â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚ USED BY: EnhancedGraphRAGRetriever                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **How Mamba COULD Be Used (Future)**

```
Query: "Find mild Alzheimer cases with atrophy"
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MAMBA SSM MODEL                                              â”‚
â”‚                                                              â”‚
â”‚ Input Prompt:                                               â”‚
â”‚ """                                                          â”‚
â”‚ You are a medical image retrieval assistant.                â”‚
â”‚                                                              â”‚
â”‚ Query: "Find mild Alzheimer cases with atrophy"            â”‚
â”‚                                                              â”‚
â”‚ Analyze and respond in JSON:                                â”‚
â”‚ {                                                            â”‚
â”‚   "intent": "local_search|global_search|hybrid_search",    â”‚
â”‚   "disease": "alzheimer|brain_tumor|parkinson|ms",          â”‚
â”‚   "severity": "mild|moderate|severe|none",                  â”‚
â”‚   "features": ["atrophy", ...],                             â”‚
â”‚   "comparison": true/false                                  â”‚
â”‚ }                                                            â”‚
â”‚ """                                                          â”‚
â”‚                                                              â”‚
â”‚ Mamba Processing:                                           â”‚
â”‚   â†’ State-space transformations                             â”‚
â”‚   â†’ Contextual understanding                                â”‚
â”‚   â†’ Intent classification                                   â”‚
â”‚                                                              â”‚
â”‚ Output:                                                     â”‚
â”‚ {                                                            â”‚
â”‚   "intent": "local_search",                                 â”‚
â”‚   "disease": "alzheimer",                                   â”‚
â”‚   "severity": "mild",                                       â”‚
â”‚   "features": ["atrophy", "hippocampus"],                   â”‚
â”‚   "comparison": false                                       â”‚
â”‚ }                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QUERY RESULT OBJECT                                          â”‚
â”‚                                                              â”‚
â”‚ QueryResult(                                                â”‚
â”‚     raw_query="Find mild Alzheimer cases with atrophy",     â”‚
â”‚     intent="local_search",                                  â”‚
â”‚     entities={                                              â”‚
â”‚         'disease': 'alzheimer',                             â”‚
â”‚         'severity': 'mild',                                 â”‚
â”‚         'features': ['atrophy']                             â”‚
â”‚     },                                                       â”‚
â”‚     embedding=np.array([0.23, -0.12, ...]),  # From CLIP   â”‚
â”‚     confidence=0.95                                         â”‚
â”‚ )                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
             Sent to EnhancedGraphRAGRetriever
             for actual image retrieval
```

---

## ğŸ”‘ **KEY COMPONENTS & THEIR ROLES**

### **1. CLIP Model** (`src/clip_embeddings.py`)

**Role**: Convert images and text to 512-dim embeddings

```python
# Images â†’ Embeddings
image = load("alzheimer_001.jpg")
image_emb = CLIP.get_image_features(image)  # 512-dim vector

# Text â†’ Embeddings
query = "Find mild Alzheimer cases"
query_emb = CLIP.get_text_features(query)   # 512-dim vector

# Same embedding space â†’ Can compare!
similarity = cosine_similarity(image_emb, query_emb)
```

**Storage**: Embeddings cached in `embeddings_cache/*.pkl`

---

### **2. SSM/Mamba** (`src/ssm.py`)

**Role**: Understand query intent and select search strategy

```python
query = "Find mild Alzheimer cases"
  â”‚
  â–¼
SSM analyzes:
  - Intent: "find" â†’ local_search
  - Entities: "mild", "Alzheimer"
  - Mode: specific retrieval
  â”‚
  â–¼
Returns: QueryResult(intent="local_search", entities={...})
```

**Storage**: Model loaded in memory (130M parameters)

---

### **3. Community Detector** (`src/community_detection.py`)

**Role**: Group similar images into hierarchical communities

```python
# Runs ONCE during graph building
embeddings = [img_001_emb, img_002_emb, ..., img_400_emb]
  â”‚
  â–¼
Level 0: Group by disease
  â†’ 4 communities (alzheimer, tumor, parkinson, ms)
  â”‚
  â–¼
Level 1: Within each disease, cluster by visual similarity
  â†’ ~16 communities (mild, moderate, severe, subtypes)
  â”‚
  â–¼
Level 2: Fine-grained within each cluster
  â†’ ~24 communities (specific patterns)
  â”‚
  â–¼
Total: 44 communities stored in graph
```

**Storage**: Community assignments stored in graph nodes

---

### **4. Knowledge Graph** (`src/graphRAG.py`)

**Role**: Store all relationships and enable graph traversal

```python
graph = {
    'nodes': {
        'img_001': {
            'embedding': [...],
            'communities': ['L0_C0', 'L1_C2', 'L2_C5'],
            'metadata': {...}
        }
    },
    'edges': [
        ('img_001', 'img_002', {'similarity': 0.87}),
        ('img_001', 'img_045', {'similarity': 0.76}),
        ...
    ]
}
```

**Storage**: NetworkX graph object in memory

---

### **5. Enhanced Retriever** (`src/enhanced_graphrag.py`)

**Role**: Orchestrate retrieval using communities and embeddings

```python
def retrieve(query):
    # 1. Process query with SSM
    query_result = ssm_processor.process_query(query)
    
    # 2. Select strategy
    if query_result.intent == "local":
        results = local_search(query_result.embedding)
    elif query_result.intent == "global":
        results = global_search(query_result)
    else:
        results = hybrid_search(query_result)
    
    # 3. Rank and return
    return top_k_results
```

**Storage**: All data structures in memory during runtime

---

## ğŸ“Š **DATA FLOW DIAGRAM**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Images (400)   â”‚  Stored on disk
â”‚   - alzheimer: 100   â”‚  balanced_data/
â”‚   - tumor: 100       â”‚
â”‚   - parkinson: 100   â”‚
â”‚   - ms: 100          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Load & Process
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIP Embedding      â”‚  Extract features
â”‚  Extractor           â”‚  512-dim vectors
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Cache to disk
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embeddings Cache     â”‚  Stored as .pkl
â”‚ - alzheimer.pkl      â”‚  embeddings_cache/
â”‚ - tumor.pkl          â”‚  
â”‚ - parkinson.pkl      â”‚  (Reload on startup)
â”‚ - ms.pkl             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Load into memory
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        IN-MEMORY DATA STRUCTURES             â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Image          â”‚  â”‚ Knowledge        â”‚  â”‚
â”‚  â”‚ Embeddings     â”‚â”€â”€â”‚ Graph            â”‚  â”‚
â”‚  â”‚ (400 Ã— 512)    â”‚  â”‚ (400 nodes,      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  75K edges)      â”‚  â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Communities    â”‚  â”‚ Metadata         â”‚  â”‚
â”‚  â”‚ (44 groups)    â”‚  â”‚ Index            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ Query comes in
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUERY PROCESSING                             â”‚
â”‚                                              â”‚
â”‚  User Query â†’ SSM â†’ Search Strategy          â”‚
â”‚             â†’ Retrieval â†’ Ranking            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ Results
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RETURN                                       â”‚
â”‚  - Top-K images                              â”‚
â”‚  - Similarity scores                         â”‚
â”‚  - Community explanations                    â”‚
â”‚  - Confidence values                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â±ï¸ **TIMING BREAKDOWN**

**Total Query Time: ~71ms**

```
Query: "Find mild Alzheimer cases"
  â”‚
  â”œâ”€ SSM Processing: ~5ms
  â”‚   â””â”€ Intent detection, entity extraction
  â”‚
  â”œâ”€ CLIP Text Embedding: ~10ms
  â”‚   â””â”€ Convert query to 512-dim vector
  â”‚
  â”œâ”€ Similarity Computation: ~40ms
  â”‚   â””â”€ Compare query vs 400 image embeddings
  â”‚
  â”œâ”€ Ranking & Filtering: ~5ms
  â”‚   â””â”€ Sort results, get top-K
  â”‚
  â””â”€ Explanation Generation: ~11ms
      â””â”€ Load metadata, community paths
  â”‚
  â–¼
Total: ~71ms
```

---

## ğŸ’¾ **MEMORY USAGE**

```
When System is Running:
  
  â”œâ”€ Image Embeddings: 400 Ã— 512 Ã— 4 bytes = ~800 KB
  â”œâ”€ Graph Structure: ~10 MB
  â”œâ”€ Communities: ~2 MB
  â”œâ”€ Metadata: ~1 MB
  â”œâ”€ CLIP Model: ~600 MB (loaded in memory)
  â””â”€ SSM Model: ~500 MB (if using Mamba)
  
  Total: ~1.1 GB RAM
```

---

## ğŸ¯ **SUMMARY**

### **Where You Are:**

âœ… **400 images** organized in 4 disease datasets  
âœ… **44 hierarchical communities** (3 levels)  
âœ… **75,625 edges** in knowledge graph  
âœ… **CLIP embeddings** (512-dim) for all images  
âœ… **Multi-strategy retrieval** (Global/Local/Hybrid)  
âœ… **72.4% P@5** performance  

### **How Storage Works:**

ğŸ“ **Disk**: Raw images + cached embeddings (.pkl files)  
ğŸ§  **Memory**: Graph, communities, embeddings loaded at runtime  
âš¡ **Speed**: Cache avoids re-computing embeddings  

### **How Retrieval Works:**

1. **Query** â†’ SSM processes intent
2. **Embedding** â†’ CLIP converts query to 512-dim vector
3. **Search** â†’ Multi-strategy (Global/Local/Hybrid)
4. **Rank** â†’ Sort by similarity, enrich with context
5. **Return** â†’ Top-K images with explanations

### **How Mamba Communicates:**

ğŸ”„ **Currently**: Rule-based intent detection (fast, simple)  
ğŸ”® **Future**: Mamba LLM for advanced query understanding  
ğŸ”— **Interface**: SSMQueryProcessor â†’ QueryResult â†’ Retriever  

---

**ğŸ‰ Your system is a complete end-to-end pipeline from raw images to interpretable retrieval results!**


